{"cells":[{"metadata":{"trusted":false},"cell_type":"code","source":"import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\npd.set_option('display.max_rows', 500)\npd.set_option('display.max_columns', 100)\n\nimport gc\nimport time\nimport pickle\nimport seaborn as sns\nfrom tqdm import tqdm\nfrom itertools import product\nimport matplotlib.pyplot as plt\nfrom xgboost import XGBRegressor\nfrom sklearn import preprocessing \nfrom xgboost import plot_importance\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import train_test_split\n\ndef plot_features(booster, figsize):    \n    fig, ax = plt.subplots(1,1,figsize=figsize)\n    return plot_importance(booster=booster, ax=ax)\n\ndef downcast_dtypes(df):\n    float_cols = [c for c in df if df[c].dtype == \"float64\"]\n    int_cols = [c for c in df if df[c].dtype in [\"int64\", \"int32\"]]\n    df[float_cols] = df[float_cols].astype(np.float16)\n    df[int_cols] = df[int_cols].astype(np.int16)\n    return df\n\nimport sys\nsys.version_info","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# 将index设置为ID，以避免稍后删除它\ntest  = pd.read_csv('/kaggle/input/competitive-data-science-predict-future-sales/test.csv').set_index('ID')\ntrain = pd.read_csv('/kaggle/input/competitive-data-science-predict-future-sales/sales_train.csv')\n\n#删除特异值\ntrain = train[train.item_price<100000]\ntrain = train[train.item_cnt_day<1001]\n#售价低于0,用中值填充\nmedian = train[(train.shop_id==32)&(train.item_id==2973)&(train.date_block_num==4)&(train.item_price>0)].item_price.median()\ntrain.loc[train.item_price<0, 'item_price'] = median\n\n#清除重复行\ntrain.drop_duplicates(subset=[\"date\",\"date_block_num\",\"shop_id\",\"item_id\",\"item_price\",\"item_cnt_day\"],keep='first',inplace=True)\n\n##有几家商店是彼此的复制品,修复训练集和测试集将其更改为同一商店编号\n# Якутск Орджоникидзе, 56\ntrain.loc[train.shop_id == 0, 'shop_id'] = 57\ntest.loc[test.shop_id == 0, 'shop_id'] = 57\n# Якутск ТЦ \"Центральный\"\ntrain.loc[train.shop_id == 1, 'shop_id'] = 58\ntest.loc[test.shop_id == 1, 'shop_id'] = 58\n# Жуковский ул. Чкалова 39м²\ntrain.loc[train.shop_id == 10, 'shop_id'] = 11\ntest.loc[test.shop_id == 10, 'shop_id'] = 11\n\n#清除训练集中在测试集中不存在的商店\ntrain = train.merge(test[['shop_id']].drop_duplicates(), how = 'inner')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#shops.csv数据--------------------------------------------------\nshops = pd.read_csv('/kaggle/input/competitive-data-science-predict-future-sales/shops.csv')\n#分解出商店所在城市\nshops.loc[shops.shop_name == 'Сергиев Посад ТЦ \"7Я\"', 'shop_name'] = 'СергиевПосад ТЦ \"7Я\"'\nshops['city'] = shops['shop_name'].str.split(' ').map(lambda x: x[0])\nshops.loc[shops.city == '!Якутск', 'city'] = 'Якутск'\nshops['shop_city'] = LabelEncoder().fit_transform(shops['city'])\n#分解出商店经营类型\nshops['shop_name1'] = shops['shop_name'].apply(lambda x: x.lower()).str.replace('[^\\w\\s]', '').str.replace('\\d+','').str.strip()\nshops['shop_type'] = shops['shop_name1'].apply(lambda x: 'мтрц' if 'мтрц' in x else 'трц' if 'трц' in x else 'трк' if 'трк' in x else 'тц' if 'тц' in x else 'тк' if 'тк' in x else 'NO_DATA')\nshops[\"shop_type\"] = shops[\"shop_type\"].map({'NO_DATA': 0 ,'мтрц': 1 ,'тк': 2 ,'трк': 3 ,'трц': 4 ,'тц': 5 })\n#更新数据\nshops = shops[['shop_id','shop_city','shop_type']]\n\n#item_categories.csv数据--------------------------------------------------\ncats = pd.read_csv('/kaggle/input/competitive-data-science-predict-future-sales/item_categories.csv')\n#分解出商品所在类别\ncats['split'] = cats['item_category_name'].str.split('-')\ncats['type'] = cats['split'].map(lambda x: x[0].strip())\ncats['item_type'] = LabelEncoder().fit_transform(cats['type'])\n# # 如果子类型是nan，就输入\ncats['subtype'] = cats['split'].map(lambda x: x[1].strip() if len(x) > 1 else x[0].strip())\ncats['item_subtype'] = LabelEncoder().fit_transform(cats['subtype'])\ncats = cats[['item_category_id','item_type','item_subtype']]\n\n#items.csv数据--------------------------------------------------\nitems = pd.read_csv('/kaggle/input/competitive-data-science-predict-future-sales/items.csv')\n\nitems['name_1'], items['name_2'] = items['item_name'].str.split('[', 1).str\nitems['name_1'], items['name_3'] = items['item_name'].str.split('(', 1).str\n\nitems['name_2'] = items['name_2'].str.replace('[^A-Za-z0-9А-Яа-я]+', ' ').str.lower()\nitems['name_3'] = items['name_3'].str.replace('[^A-Za-z0-9А-Яа-я]+', ' ').str.lower()\nitems = items.fillna('0')\n\nitems['name_1'] = LabelEncoder().fit_transform(items['name_1'])\nitems['name_2'] = LabelEncoder().fit_transform(items['name_2'])\nitems['name_3'] = LabelEncoder().fit_transform(items['name_3'])\n\nitems = items[['item_id','item_category_id','name_1','name_2','name_3']]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"特征添加"},{"metadata":{"trusted":false},"cell_type":"code","source":"#对于每个月，我们从该月的所有商店/项目组合创建一个网格\nmatrix = []\ncols = ['date_block_num','shop_id','item_id']\nfor i in train['date_block_num'].unique():\n    sales = train[train.date_block_num==i]\n    matrix.append(np.array(list(product([i], sales.shop_id.unique(), sales.item_id.unique())), dtype='int16'))\nmatrix = pd.DataFrame(np.vstack(matrix), columns=cols)\nmatrix['date_block_num'] = matrix['date_block_num'].astype(np.int8)\nmatrix['shop_id'] = matrix['shop_id'].astype(np.int8)\nmatrix['item_id'] = matrix['item_id'].astype(np.int16)\nmatrix.sort_values(cols,inplace=True)\n\n#求每月在该商店该商品的售出量:item_cnt_month\ngroup = train.groupby(['date_block_num','shop_id','item_id']).agg({'item_cnt_day': ['sum']})\ngroup.columns = ['item_cnt_month']\ngroup.reset_index(inplace=True)\n\nmatrix = pd.merge(matrix, group, on=cols, how='left')\nmatrix['item_cnt_month'] = (matrix['item_cnt_month'].fillna(0).clip(0,20).astype(np.float16))\n\n#要使用时间技巧，请将测试对附加到矩阵中\ntest['date_block_num'] = 34\nmatrix = pd.concat([matrix, test], ignore_index=True, sort=False, keys=cols)\nmatrix.fillna(0, inplace=True) # 34 month\ndel test\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"matrix = pd.merge(matrix, shops, on=['shop_id'], how='left')\nmatrix = pd.merge(matrix, items, on=['item_id'], how='left')\nmatrix = pd.merge(matrix, cats, on=['item_category_id'], how='left')\n\ndel shops,items,cats\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#添加月,日变量\nmatrix['year']  =  matrix['date_block_num']/12+2013\nmatrix['month'] = matrix['date_block_num'] % 12\ndays = pd.Series([31,28,31,30,31,30,31,31,30,31,30,31])\nmatrix['days']  = matrix['month'].map(days).astype(np.int8)\nmatrix['year']  = matrix['year'].astype(np.int16)\nprint(matrix.shape)\nmatrix.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"def lag_feature(df, lags, col):\n    tmp = df[['date_block_num','shop_id','item_id',col]]\n    for i in lags:\n        shifted = tmp.copy()\n        shifted.columns = ['date_block_num','shop_id','item_id', col+'_lag_'+str(i)]\n        shifted['date_block_num'] += i\n        df = pd.merge(df, shifted, on=['date_block_num','shop_id','item_id'], how='left')\n    return df\n\ndef tianjia1(list_names,list_num):\n    global matrix\n    str1 = list_names[0]\n    for i in range(1,len(list_names)):\n        str1 = str1+'_and_'+list_names[i]\n    str1 = str1+'_avg_item_cnt'\n    \n    group = matrix.groupby(list_names).agg({'item_cnt_month': ['mean']})\n    group.columns = [str1]\n    group.reset_index(inplace=True)\n\n    matrix = pd.merge(matrix, group, on=list_names, how='left')\n    matrix[str1] = matrix[str1].astype(np.float16)\n    matrix = lag_feature(matrix, list_num, str1)\n    matrix.drop([str1], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#1时间item_cnt_month_lag\nmatrix = lag_feature(matrix, [1,2,3], 'item_cnt_month')\n\ntianjia1(['date_block_num'],[1])\n\ntianjia1(['date_block_num', 'item_id'],[1,2,3])\ntianjia1(['date_block_num', 'shop_id'],[1,2,3])\n\ntianjia1(['date_block_num', 'item_category_id'],[1])\ntianjia1(['date_block_num', 'shop_id', 'item_category_id'],[1])\ntianjia1(['date_block_num', 'shop_id', 'item_id'],[1])\n\nprint(matrix.shape)\nmatrix.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"group = train.groupby(['item_id']).agg({'item_price': ['mean']})\ngroup.columns = ['item_avg_item_price']\ngroup.reset_index(inplace=True)\n\nmatrix = pd.merge(matrix, group, on=['item_id'], how='left')\nmatrix['item_avg_item_price'] = matrix['item_avg_item_price'].astype(np.float16)\n\ngroup = train.groupby(['date_block_num','item_id']).agg({'item_price': ['mean']})\ngroup.columns = ['date_item_avg_item_price']\ngroup.reset_index(inplace=True)\n\nmatrix = pd.merge(matrix, group, on=['date_block_num','item_id'], how='left')\nmatrix['date_item_avg_item_price'] = matrix['date_item_avg_item_price'].astype(np.float16)\n\nlags = [1,2,3,4,5,6]\nmatrix = lag_feature(matrix, lags, 'date_item_avg_item_price')\n\nfor i in lags:\n    matrix['delta_price_lag_'+str(i)] = \\\n        (matrix['date_item_avg_item_price_lag_'+str(i)] - matrix['item_avg_item_price']) / matrix['item_avg_item_price']\n\ndef select_trend(row):\n    for i in lags:\n        if row['delta_price_lag_'+str(i)]:\n            return row['delta_price_lag_'+str(i)]\n    return 0\n    \nmatrix['delta_price_lag'] = matrix.apply(select_trend, axis=1)\nmatrix['delta_price_lag'] = matrix['delta_price_lag'].astype(np.float16)\nmatrix['delta_price_lag'].fillna(0, inplace=True)\n\nfetures_to_drop = ['item_avg_item_price', 'date_item_avg_item_price']\nfor i in lags:\n    fetures_to_drop += ['date_item_avg_item_price_lag_'+str(i)]\n    fetures_to_drop += ['delta_price_lag_'+str(i)]\n\nmatrix.drop(fetures_to_drop, axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"ts = time.time()\ncache = {}\nmatrix['item_shop_last_sale'] = -1\nmatrix['item_shop_last_sale'] = matrix['item_shop_last_sale'].astype(np.int8)\nfor idx, row in matrix.iterrows():    \n    key = str(row.item_id)+' '+str(row.shop_id)\n    if key not in cache:\n        if row.item_cnt_month!=0:\n            cache[key] = row.date_block_num\n    else:\n        last_date_block_num = cache[key]\n        matrix.at[idx, 'item_shop_last_sale'] = row.date_block_num - last_date_block_num\n        cache[key] = row.date_block_num         \n\ncache = {}\nmatrix['item_last_sale'] = -1\nmatrix['item_last_sale'] = matrix['item_last_sale'].astype(np.int8)\nfor idx, row in matrix.iterrows():    \n    key = row.item_id\n    if key not in cache:\n        if row.item_cnt_month!=0:\n            cache[key] = row.date_block_num\n    else:\n        last_date_block_num = cache[key]\n        if row.date_block_num>last_date_block_num:\n            matrix.at[idx, 'item_last_sale'] = row.date_block_num - last_date_block_num\n            cache[key] = row.date_block_num         \ntime.time() - ts","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"matrix['item_first_sale'] = matrix['date_block_num'] - matrix.groupby('item_id')['date_block_num'].transform('min')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"ts = time.time()\ndef fill_na(df):\n    for col in df.columns:\n        if ('_lag_' in col) & (df[col].isnull().any()):\n            if ('item_cnt' in col):\n                df[col].fillna(0, inplace=True)         \n    return df\nmatrix = matrix[matrix.date_block_num >3]\nmatrix = fill_na(matrix)\nmatrix = downcast_dtypes(matrix)\ntime.time() - ts\nprint(matrix.shape)\nmatrix.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"matrix.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"matrix.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"matrix.to_pickle('data2.pkl')\ndel matrix\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"data = pd.read_pickle('data2.pkl')\ndata = data[[\n    'date_block_num', \n    'shop_id', \n    'item_id', \n    'item_cnt_month', \n#     'shop_city',\n    'shop_type', \n    'item_category_id',\n#     'item_type', \n    'name_1',\n    'name_2',\n    'name_3',\n    'item_subtype',\n    'year',\n    'month',\n    'days', \n    'item_cnt_month_lag_1', \n    'item_cnt_month_lag_2',\n    'item_cnt_month_lag_3', \n    'date_block_num_avg_item_cnt_lag_1',\n    'date_block_num_and_item_id_avg_item_cnt_lag_1',\n    'date_block_num_and_item_id_avg_item_cnt_lag_2',\n    'date_block_num_and_item_id_avg_item_cnt_lag_3',\n    'date_block_num_and_shop_id_avg_item_cnt_lag_1',\n    'date_block_num_and_shop_id_avg_item_cnt_lag_2',\n    'date_block_num_and_shop_id_avg_item_cnt_lag_3',\n    'date_block_num_and_item_category_id_avg_item_cnt_lag_1',\n    'date_block_num_and_shop_id_and_item_category_id_avg_item_cnt_lag_1',\n    'date_block_num_and_shop_id_and_item_id_avg_item_cnt_lag_1',\n    'delta_price_lag', \n    'item_shop_last_sale', \n    'item_last_sale',\n    'item_first_sale'\n]]\n\n\n\n\nX_valid = data[data.date_block_num == 33].drop(['item_cnt_month'], axis=1)\nY_valid = data[data.date_block_num == 33]['item_cnt_month']\n\nX_zong = data[data.date_block_num < 33].drop(['item_cnt_month'], axis=1)\nY_zong = data[data.date_block_num < 33]['item_cnt_month']\n\n# 总得切分一下数据咯（训练集和测试集）\nX_train, X_test, y_train, y_test = train_test_split(X_valid,Y_valid,test_size = 0.25)\n\nX_tests = data[data.date_block_num == 34].drop(['item_cnt_month'], axis=1)\n\nxx = pd.concat([X_zong,X_train])\nyy = pd.concat([Y_zong,y_train])\n\ndel data,X_valid,Y_valid,X_train,y_train,X_zong,Y_zong\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"print(xx.shape)\nxx.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"xx.to_pickle('xx.pkl')\nyy.to_pickle('yy.pkl')\n\nX_test.to_pickle('X_test.pkl')\ny_test.to_pickle('y_test.pkl')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"ts = time.time()\nmodel = XGBRegressor(\n    max_depth=10,\n    n_estimators=100,\n    min_child_weight=0.5, \n    colsample_bytree=0.9, \n    subsample=0.8, \n    num_round = 10000,\n    nthread = 16,\n    eta=0.1,\n    seed=1)\n\nmodel.fit(xx, yy, eval_metric=\"rmse\", eval_set=[(xx,yy),(X_test,y_test)], verbose=True, early_stopping_rounds = 10)\ntime.time() - ts","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"Y_tests = model.predict(X_tests).clip(0, 20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"test  = pd.read_csv('/kaggle/input/competitive-data-science-predict-future-sales/test.csv').set_index('ID')\nsubmission = pd.DataFrame({\n    \"ID\": test.index, \n    \"item_cnt_month\": Y_tests\n})\nsubmission.to_csv('xgb_submission1.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"plot_features(model, (10,14))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.0"}},"nbformat":4,"nbformat_minor":1}