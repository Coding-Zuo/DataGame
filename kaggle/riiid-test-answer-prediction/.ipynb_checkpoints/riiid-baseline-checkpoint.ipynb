{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Riiid Baseline"},{"metadata":{},"cell_type":"markdown","source":"## Import libraries"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import random\nfrom collections import defaultdict\nfrom time import time\nimport gc\nimport pickle\n\nimport numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_auc_score\nimport lightgbm as lgb\n# import optuna.integration.lightgbm as lgb\n\nfrom tqdm.notebook import tqdm\n\nimport riiideducation\n\ntry:\n    env = riiideducation.make_env()\n    iter_test = env.iter_test()\nexcept:\n    pass","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Load data"},{"metadata":{"trusted":true},"cell_type":"code","source":"# nrows = 10_000_000","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"start = time()\n# train = pd.read_hdf('../input/riiid-train-data-multiple-formats/riiid_train.h5', stop=nrows)\n\nquestion_contents = pd.read_pickle('../input/riiid-preprocess-data/user_content.pkl')\nquestions = pd.read_pickle('../input/riiid-preprocess-data/questions.pkl')\n\nwith open('../input/riiid-preprocess-data/user_id_idxs.pkl', 'rb') as f:\n    user_id_idxs = pickle.load(f)\n\nprint(f'{time() - start:.2f}')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Split to feature-generating data and train data"},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_feature_train_val_idxs(user_id_idxs, feature_size, train_size, val_size, new_user_frac=.2):\n    feature_idxs, train_idxs, val_idxs = [], [], []\n    np.random.seed(42)\n\n    for indices in random.sample(list(user_id_idxs), len(user_id_idxs)):\n        if len(feature_idxs) > feature_size:\n            break\n\n        if len(val_idxs) < val_size:\n            if np.random.rand() < new_user_frac:\n                val_idxs.extend(indices)\n            else:\n                offset = np.random.randint(len(indices)//2, len(indices))\n                feature_idxs.extend(indices[:len(indices)//2])\n                train_idxs.extend(indices[len(indices)//2:offset])\n                val_idxs.extend(indices[offset:])\n        else:\n            if len(train_idxs) < train_size:\n                feature_idxs.extend(indices[:len(indices)//2])\n                train_idxs.extend(indices[len(indices)//2:])\n            else:\n                feature_idxs.extend(indices)\n    return feature_idxs, train_idxs, val_idxs","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_size = 50_000_000\ntrain_size = 30_000_000\nval_size = 2_500_000\n\nstart = time()\nfeature_idxs, train_idxs, val_idxs = get_feature_train_val_idxs(user_id_idxs, \n                                                                feature_size, \n                                                                train_size, \n                                                                val_size, \n                                                                new_user_frac=.2)\n\nprint(len(feature_idxs), len(train_idxs), len(val_idxs))\nprint(f'{time() - start:.2f}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_df = question_contents.loc[feature_idxs]\ntrain_df = question_contents.loc[train_idxs]\nval_df = question_contents.loc[val_idxs]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del question_contents, feature_idxs, train_idxs, val_idxs\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Feature engineering"},{"metadata":{"trusted":true},"cell_type":"code","source":"target = [\"answered_correctly\"]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Users_state"},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_users_state(feature_df):\n    users_state = defaultdict(lambda:{\n        'user_accuracy':0.660, \n        'correctly_answered_content_cnt':0, \n        'answered_content_cnt':0, \n        'user_content_attempts':defaultdict(lambda:0)\n    })\n\n    for user_id, content_id, answer in feature_df[['user_id', 'content_id', 'answered_correctly']].values:\n        if users_state[user_id][\"user_content_attempts\"][content_id] < 5:\n            users_state[user_id][\"user_content_attempts\"][content_id] += 1\n\n        users_state[user_id][\"correctly_answered_content_cnt\"] += answer\n        users_state[user_id][\"answered_content_cnt\"] += 1\n\n        if users_state[user_id][\"answered_content_cnt\"] >= 1:\n            users_state[user_id][\"user_accuracy\"] = users_state[user_id][\"correctly_answered_content_cnt\"] \\\n            / users_state[user_id][\"answered_content_cnt\"]\n    \n    return users_state","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"start = time()\nusers_state = get_users_state(feature_df)\nprint(f'{time() - start:.2f}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del feature_df\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Update users_state"},{"metadata":{"trusted":true},"cell_type":"code","source":"def update_users_state(users_state, prev_test_df):\n    for user_id, content_id, answer in prev_test_df[['user_id', 'content_id', 'answered_correctly']].values:\n        if users_state[user_id][\"user_content_attempts\"][content_id] < 5:\n            users_state[user_id][\"user_content_attempts\"][content_id] += 1\n\n        users_state[user_id][\"correctly_answered_content_cnt\"] += answer\n        users_state[user_id][\"answered_content_cnt\"] += 1\n\n        if users_state[user_id][\"answered_content_cnt\"] >= 1:\n            users_state[user_id][\"user_accuracy\"] = users_state[user_id][\"correctly_answered_content_cnt\"] / users_state[user_id][\"answered_content_cnt\"]\n\n    return users_state","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def update_data(data, users_state, questions):\n    start = time()\n    \n    user_accuracy = []\n    answered_content_cnt = []\n    correctly_answered_content_cnt = []\n    user_content_attempts = []\n    \n    data = data.copy()\n    \n    for user_id, content_id in tqdm(data[['user_id', 'content_id']].values):\n        user_accuracy.append(users_state[user_id]['user_accuracy'])\n        answered_content_cnt.append(users_state[user_id]['answered_content_cnt'])\n        correctly_answered_content_cnt.append(users_state[user_id]['correctly_answered_content_cnt'])\n        user_content_attempts.append(min(5, users_state[user_id]['user_content_attempts'][content_id] + 1))\n    \n    data['user_accuracy'] = user_accuracy\n    data['answered_content_cnt'] = answered_content_cnt\n    data['correctly_answered_content_cnt'] = correctly_answered_content_cnt\n    data['user_content_attempts'] = user_content_attempts\n    \n    data = data.merge(questions, how='left', on='content_id')\n    \n    data['hmean_user_content_accuracy'] = 2 * (data['user_accuracy'] * data['content_accuracy']) / (data['user_accuracy'] + data['content_accuracy'])\n    data['hmean_user_part_accuracy'] = 2 * (data['user_accuracy'] * data['part_accuracy']) / (data['user_accuracy'] + data['part_accuracy'])\n    data['hmean_user_tags_accuracy'] = 2 * (data['user_accuracy'] * data['tags_accuracy']) / (data['user_accuracy'] + data['tags_accuracy'])\n    \n    data['prior_question_elapsed_time'].fillna(23916, inplace=True)\n#     data['prior_question_had_explanation'].fillna(False, inplace=True)\n    \n    print(f'{time() - start:.2f}')\n    return data","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Train model"},{"metadata":{"trusted":true},"cell_type":"code","source":"updated_train_df = update_data(train_df, users_state, questions)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"users_state = update_users_state(users_state, updated_train_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"updated_val_df = update_data(val_df, users_state, questions)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del train_df, val_df\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features = [\n    # user-based features\n    \"user_accuracy\",\n    \"correctly_answered_content_cnt\",\n    \"answered_content_cnt\",\n    \n    # content-based features\n    \"content_accuracy\",\n#     'tags_accuracy',\n#     'part_accuracy',\n    \n    # given features\n    'prior_question_elapsed_time',\n    \n    # other features\n    \"hmean_user_content_accuracy\",\n#     \"hmean_user_tags_accuracy\",\n#     \"hmean_user_part_accuracy\",\n    'user_content_attempts'\n]\n\ncategorical_features = [\n    \"part\",\n#     'prior_question_had_explanation',\n    'tags'\n]\n\ntrain_data = lgb.Dataset(\n    data=updated_train_df[features + categorical_features],\n    label=updated_train_df[target],\n    categorical_feature=categorical_features,\n    free_raw_data=False\n)\n\nval_data = lgb.Dataset(\n    data=updated_val_df[features + categorical_features],\n    label=updated_val_df[target],\n    categorical_feature=categorical_features,\n    free_raw_data=False,\n    reference=train_data\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del updated_train_df\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lgbm_params = {\n    \"objective\":\"binary\",\n    \"metric\":\"auc\"\n}\n\nevals_result = {}\n\nmodel = None\n\nstart = time()\nmodel = lgb.train(\n    params = lgbm_params,\n    train_set = train_data, \n    valid_sets = [train_data, val_data], \n    init_model = model,\n    num_boost_round = 10_000,\n    verbose_eval = 10,\n    early_stopping_rounds = 50,\n    evals_result = evals_result,\n    categorical_feature = categorical_features\n)\n\nmodel.save_model('model.txt')\n\nprint(f'{time() - start:.2f}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_importances = model.feature_importance(\"gain\")\n\nfeature_importances /= np.sum(feature_importances)\n\nfor i in range(len(features)):\n    print(f\"{features[i]}: {feature_importances[i]:.3f}\")\n  \nfor i in range(len(categorical_features)):\n    print(f\"{categorical_features[i]}: {feature_importances[len(features)+i]:.3f}\")\n    \nlgb.plot_importance(model, importance_type='gain', dpi=100)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_importances = model.feature_importance(\"split\")\n\nfor i in range(len(features)):\n    print(f\"{features[i]}: {feature_importances[i]}\")\n\nfor i in range(len(categorical_features)):\n    print(f\"{categorical_features[i]}: {feature_importances[len(features)+i]:.2f}\")\n\nlgb.plot_importance(model, importance_type = 'split', dpi=100)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"raw","source":"test_dtype = {'row_id': 'int64',\n     'timestamp': 'int64',\n     'user_id': 'int32',\n     'content_id': 'int16',\n     'content_type_id': 'int8',\n     'prior_question_elapsed_time': 'float32',\n     'prior_question_had_explanation': 'category'\n}\n\nexample_test = pd.read_csv('../input/riiid-test-answer-prediction/example_test.csv')\n\nexample_test = update_data(example_test, users_state, questions)\n\nexample_test = example_test.astype(test_dtype)\n\nmodel.predict(example_test[features + categorical_features], num_iteration=model.best_iteration)"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_dtype = {\n    'row_id': 'int64',\n    'timestamp': 'int64',\n    'user_id': 'int32',\n    'content_id': 'int16',\n    'content_type_id': 'int8',\n    'prior_question_elapsed_time': 'float32',\n#     'prior_question_had_explanation': 'category'\n}\n\nusers_state = update_users_state(users_state, updated_val_df)\n\nprev_test_df = None\n\nfor idx, (test_df, _) in tqdm(enumerate(iter_test)):\n    if prev_test_df is not None:\n        prev_test_df['answered_correctly'] = eval(test_df['prior_group_answers_correct'].iloc[0])\n        users_state = update_users_state(users_state, prev_test_df[lambda x:x['content_type_id'] == 0])\n        \n        train_data = val_data\n        \n        val_data = lgb.Dataset(data=prev_test_df[features+categorical_features],\n                               label=prev_test_df[target],\n                               categorical_feature=categorical_features,\n                               free_raw_data=False,\n                               reference=train_data\n                              )\n        \n        model = lgb.train(\n            params = lgbm_params,\n            train_set = train_data,\n            valid_sets = [train_data, val_data],\n            init_model = model,\n            keep_training_booster=True,\n            num_boost_round = 10_000,\n            verbose_eval = 10,\n            early_stopping_rounds = 50,\n            categorical_feature = categorical_features\n            )\n    \n    test_df = update_data(test_df, users_state, questions)\n    \n    test_df = test_df.astype(test_dtype)\n\n    test_df['answered_correctly'] = model.predict(test_df[features + categorical_features], \n                                                  num_iteration=model.best_iteration)\n        \n    env.predict(test_df.loc[test_df['content_type_id'] == 0, ['row_id', 'answered_correctly']])\n    \n    prev_test_df = test_df.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.read_csv('./submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"display(submission)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}