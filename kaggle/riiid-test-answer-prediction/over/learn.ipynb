{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import time\n",
    "import gzip\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import datatable as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import random\n",
    "\n",
    "random.seed(1)\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.max_rows', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA_PATH = '../input/riiid-test-answer-prediction/'\n",
    "MY_DATA_PATH = './my_data/'\n",
    "CACHE_PATH = './lgb1215weights/'\n",
    "\n",
    "DATA_PATH = '/home/zuoyuhui/datasets/riid准确回答/'\n",
    "file_train = 'train.csv'\n",
    "file_questions = 'questions.csv'\n",
    "file_lectures = 'lectures.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(CACHE_PATH):\n",
    "    os.mkdir(CACHE_PATH)\n",
    "    \n",
    "    \n",
    "DEBUG = True\n",
    "OFFLINE = True\n",
    "CV5 = False #联系cv5\n",
    "CV = False #普通cut\n",
    "\n",
    "# if OFFLINE:\n",
    "#     nrows = 1250000\n",
    "# else:\n",
    "#     nrows = None\n",
    "\n",
    "if DEBUG:\n",
    "    MY_DATA_PATH = f'{MY_DATA_PATH}/debug/'\n",
    "    CACHE_PATH = f'{CACHE_PATH}/debug/'\n",
    "    if not os.path.exists(CACHE_PATH):\n",
    "        os.mkdir(CACHE_PATH)\n",
    "        \n",
    "config_file = f'{CACHE_PATH}/config.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 1</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "      <th>Unnamed: 6</th>\n",
       "      <th>Unnamed: 7</th>\n",
       "      <th>Unnamed: 8</th>\n",
       "      <th>Unnamed: 9</th>\n",
       "      <th>Unnamed: 10</th>\n",
       "      <th>Unnamed: 11</th>\n",
       "      <th>Unnamed: 12</th>\n",
       "      <th>Unnamed: 13</th>\n",
       "      <th>Unnamed: 14</th>\n",
       "      <th>-</th>\n",
       "      <th>Unnamed: 16</th>\n",
       "      <th>Unnamed: 17</th>\n",
       "      <th>Unnamed: 18</th>\n",
       "      <th>Unnamed: 19</th>\n",
       "      <th>Unnamed: 20</th>\n",
       "      <th>Unnamed: 21</th>\n",
       "      <th>Unnamed: 22</th>\n",
       "      <th>Unnamed: 23</th>\n",
       "      <th>Unnamed: 24</th>\n",
       "      <th>Unnamed: 25</th>\n",
       "      <th>Unnamed: 26</th>\n",
       "      <th>Unnamed: 27</th>\n",
       "      <th>Crank Angle</th>\n",
       "      <th>Cylinder Volume</th>\n",
       "      <th>Crank Angle.1</th>\n",
       "      <th>Cylinder Volume.1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-360.0</td>\n",
       "      <td>-0.004102</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>1.38103</td>\n",
       "      <td>-360.0</td>\n",
       "      <td>1.49343</td>\n",
       "      <td>-360.0</td>\n",
       "      <td>1.49343</td>\n",
       "      <td>-360.0</td>\n",
       "      <td>1.49343</td>\n",
       "      <td>-360.0</td>\n",
       "      <td>1.49343</td>\n",
       "      <td>-360.0</td>\n",
       "      <td>0.00612</td>\n",
       "      <td>-360.0</td>\n",
       "      <td>-12.6690</td>\n",
       "      <td>-120.0</td>\n",
       "      <td>1.274</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>663.524</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>-2.26684</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-360.0</td>\n",
       "      <td>-0.001712</td>\n",
       "      <td>-360.0</td>\n",
       "      <td>-0.006762</td>\n",
       "      <td>-360.00</td>\n",
       "      <td>0.061728</td>\n",
       "      <td>-360.00</td>\n",
       "      <td>42.7702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-359.0</td>\n",
       "      <td>-0.004108</td>\n",
       "      <td>-179.0</td>\n",
       "      <td>1.38635</td>\n",
       "      <td>-359.5</td>\n",
       "      <td>1.50003</td>\n",
       "      <td>-359.0</td>\n",
       "      <td>1.50567</td>\n",
       "      <td>-359.0</td>\n",
       "      <td>1.50567</td>\n",
       "      <td>-359.0</td>\n",
       "      <td>1.50567</td>\n",
       "      <td>-359.0</td>\n",
       "      <td>0.00284</td>\n",
       "      <td>-359.0</td>\n",
       "      <td>-12.6691</td>\n",
       "      <td>-118.0</td>\n",
       "      <td>1.334</td>\n",
       "      <td>-29.0</td>\n",
       "      <td>670.418</td>\n",
       "      <td>-29.0</td>\n",
       "      <td>-2.76110</td>\n",
       "      <td>-29.0</td>\n",
       "      <td>-2.51397</td>\n",
       "      <td>-359.0</td>\n",
       "      <td>-0.001700</td>\n",
       "      <td>-359.0</td>\n",
       "      <td>-0.006766</td>\n",
       "      <td>-359.95</td>\n",
       "      <td>0.061729</td>\n",
       "      <td>-359.95</td>\n",
       "      <td>42.7703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-358.0</td>\n",
       "      <td>-0.004098</td>\n",
       "      <td>-178.0</td>\n",
       "      <td>1.41263</td>\n",
       "      <td>-359.0</td>\n",
       "      <td>1.50567</td>\n",
       "      <td>-358.0</td>\n",
       "      <td>1.49911</td>\n",
       "      <td>-358.0</td>\n",
       "      <td>1.49911</td>\n",
       "      <td>-358.0</td>\n",
       "      <td>1.49911</td>\n",
       "      <td>-358.0</td>\n",
       "      <td>-0.01710</td>\n",
       "      <td>-358.0</td>\n",
       "      <td>-12.6690</td>\n",
       "      <td>-116.0</td>\n",
       "      <td>1.328</td>\n",
       "      <td>-28.0</td>\n",
       "      <td>677.426</td>\n",
       "      <td>-28.0</td>\n",
       "      <td>-2.43798</td>\n",
       "      <td>-28.0</td>\n",
       "      <td>-5.11351</td>\n",
       "      <td>-358.0</td>\n",
       "      <td>-0.001696</td>\n",
       "      <td>-358.0</td>\n",
       "      <td>-0.006760</td>\n",
       "      <td>-359.90</td>\n",
       "      <td>0.061729</td>\n",
       "      <td>-359.90</td>\n",
       "      <td>42.7709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-357.0</td>\n",
       "      <td>-0.004100</td>\n",
       "      <td>-177.0</td>\n",
       "      <td>1.42679</td>\n",
       "      <td>-358.5</td>\n",
       "      <td>1.44443</td>\n",
       "      <td>-357.0</td>\n",
       "      <td>1.47147</td>\n",
       "      <td>-357.0</td>\n",
       "      <td>1.47147</td>\n",
       "      <td>-357.0</td>\n",
       "      <td>1.47147</td>\n",
       "      <td>-357.0</td>\n",
       "      <td>-0.02568</td>\n",
       "      <td>-357.0</td>\n",
       "      <td>-12.6695</td>\n",
       "      <td>-114.0</td>\n",
       "      <td>1.861</td>\n",
       "      <td>-27.0</td>\n",
       "      <td>685.179</td>\n",
       "      <td>-27.0</td>\n",
       "      <td>-2.66017</td>\n",
       "      <td>-27.0</td>\n",
       "      <td>-7.66259</td>\n",
       "      <td>-357.0</td>\n",
       "      <td>-0.001694</td>\n",
       "      <td>-357.0</td>\n",
       "      <td>-0.006780</td>\n",
       "      <td>-359.85</td>\n",
       "      <td>0.061731</td>\n",
       "      <td>-359.85</td>\n",
       "      <td>42.7717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-356.0</td>\n",
       "      <td>-0.004120</td>\n",
       "      <td>-176.0</td>\n",
       "      <td>1.41187</td>\n",
       "      <td>-358.0</td>\n",
       "      <td>1.49911</td>\n",
       "      <td>-356.0</td>\n",
       "      <td>1.44775</td>\n",
       "      <td>-356.0</td>\n",
       "      <td>1.44775</td>\n",
       "      <td>-356.0</td>\n",
       "      <td>1.44775</td>\n",
       "      <td>-356.0</td>\n",
       "      <td>-0.02714</td>\n",
       "      <td>-356.0</td>\n",
       "      <td>-12.6697</td>\n",
       "      <td>-112.0</td>\n",
       "      <td>1.401</td>\n",
       "      <td>-26.0</td>\n",
       "      <td>692.056</td>\n",
       "      <td>-26.0</td>\n",
       "      <td>-2.87398</td>\n",
       "      <td>-26.0</td>\n",
       "      <td>-10.42970</td>\n",
       "      <td>-356.0</td>\n",
       "      <td>-0.001712</td>\n",
       "      <td>-356.0</td>\n",
       "      <td>-0.006788</td>\n",
       "      <td>-359.80</td>\n",
       "      <td>0.061732</td>\n",
       "      <td>-359.80</td>\n",
       "      <td>42.7729</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Unnamed: 1  Unnamed: 2  Unnamed: 3  Unnamed: 4  Unnamed: 5  \\\n",
       "0      -360.0   -0.004102      -180.0     1.38103      -360.0     1.49343   \n",
       "1      -359.0   -0.004108      -179.0     1.38635      -359.5     1.50003   \n",
       "2      -358.0   -0.004098      -178.0     1.41263      -359.0     1.50567   \n",
       "3      -357.0   -0.004100      -177.0     1.42679      -358.5     1.44443   \n",
       "4      -356.0   -0.004120      -176.0     1.41187      -358.0     1.49911   \n",
       "\n",
       "   Unnamed: 6  Unnamed: 7  Unnamed: 8  Unnamed: 9  Unnamed: 10  Unnamed: 11  \\\n",
       "0      -360.0     1.49343      -360.0     1.49343       -360.0      1.49343   \n",
       "1      -359.0     1.50567      -359.0     1.50567       -359.0      1.50567   \n",
       "2      -358.0     1.49911      -358.0     1.49911       -358.0      1.49911   \n",
       "3      -357.0     1.47147      -357.0     1.47147       -357.0      1.47147   \n",
       "4      -356.0     1.44775      -356.0     1.44775       -356.0      1.44775   \n",
       "\n",
       "   Unnamed: 12  Unnamed: 13  Unnamed: 14        -  Unnamed: 16  Unnamed: 17  \\\n",
       "0       -360.0      0.00612       -360.0 -12.6690       -120.0        1.274   \n",
       "1       -359.0      0.00284       -359.0 -12.6691       -118.0        1.334   \n",
       "2       -358.0     -0.01710       -358.0 -12.6690       -116.0        1.328   \n",
       "3       -357.0     -0.02568       -357.0 -12.6695       -114.0        1.861   \n",
       "4       -356.0     -0.02714       -356.0 -12.6697       -112.0        1.401   \n",
       "\n",
       "   Unnamed: 18  Unnamed: 19  Unnamed: 20  Unnamed: 21  Unnamed: 22  \\\n",
       "0        -30.0      663.524        -30.0     -2.26684        -30.0   \n",
       "1        -29.0      670.418        -29.0     -2.76110        -29.0   \n",
       "2        -28.0      677.426        -28.0     -2.43798        -28.0   \n",
       "3        -27.0      685.179        -27.0     -2.66017        -27.0   \n",
       "4        -26.0      692.056        -26.0     -2.87398        -26.0   \n",
       "\n",
       "   Unnamed: 23  Unnamed: 24  Unnamed: 25  Unnamed: 26  Unnamed: 27  \\\n",
       "0      0.00000       -360.0    -0.001712       -360.0    -0.006762   \n",
       "1     -2.51397       -359.0    -0.001700       -359.0    -0.006766   \n",
       "2     -5.11351       -358.0    -0.001696       -358.0    -0.006760   \n",
       "3     -7.66259       -357.0    -0.001694       -357.0    -0.006780   \n",
       "4    -10.42970       -356.0    -0.001712       -356.0    -0.006788   \n",
       "\n",
       "   Crank Angle  Cylinder Volume  Crank Angle.1  Cylinder Volume.1  \n",
       "0      -360.00         0.061728        -360.00            42.7702  \n",
       "1      -359.95         0.061729        -359.95            42.7703  \n",
       "2      -359.90         0.061729        -359.90            42.7709  \n",
       "3      -359.85         0.061731        -359.85            42.7717  \n",
       "4      -359.80         0.061732        -359.80            42.7729  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_excel('1.xlsx',sheet_name = \"CA\",skiprows = 2)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Crank Angle.1</th>\n",
       "      <th>Cylinder Volume.1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-360.0</td>\n",
       "      <td>42.7702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-359.0</td>\n",
       "      <td>42.8389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>-358.0</td>\n",
       "      <td>43.0453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>-357.0</td>\n",
       "      <td>43.3890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>-356.0</td>\n",
       "      <td>43.8700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17900</th>\n",
       "      <td>535.0</td>\n",
       "      <td>734.7280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17920</th>\n",
       "      <td>536.0</td>\n",
       "      <td>735.0590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17940</th>\n",
       "      <td>537.0</td>\n",
       "      <td>735.3160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17960</th>\n",
       "      <td>538.0</td>\n",
       "      <td>735.5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17980</th>\n",
       "      <td>539.0</td>\n",
       "      <td>735.6100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>900 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Crank Angle.1  Cylinder Volume.1\n",
       "0             -360.0            42.7702\n",
       "20            -359.0            42.8389\n",
       "40            -358.0            43.0453\n",
       "60            -357.0            43.3890\n",
       "80            -356.0            43.8700\n",
       "...              ...                ...\n",
       "17900          535.0           734.7280\n",
       "17920          536.0           735.0590\n",
       "17940          537.0           735.3160\n",
       "17960          538.0           735.5000\n",
       "17980          539.0           735.6100\n",
       "\n",
       "[900 rows x 2 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def is_number(s):\n",
    "    s = str(s)\n",
    "    \n",
    "    if s.count('.') == 1:#小数\n",
    "        new_s = s.split('.')\n",
    "        left_num = new_s[0]\n",
    "        right_num = new_s[1]\n",
    "        if right_num=='0':\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "T = data[(-360 <= data['Crank Angle.1']) & (data['Crank Angle.1'] <= 539)][['Crank Angle.1','Cylinder Volume.1']]\n",
    "T=T[T['Crank Angle.1'].apply(is_number)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_pickle(dic,save_path):\n",
    "    with gzip.open(save_path,'wb') as f:\n",
    "        pickle.dump(dic,f)\n",
    "        \n",
    "def load_pickle(load_path):\n",
    "    with gzip.open(load_path,'rb') as f:\n",
    "        message_dict = pickle.load(f)\n",
    "    return message_dict\n",
    "\n",
    "#定义内存压缩方法\n",
    "def reduce_mem_usage(df,verbose=True):\n",
    "    start_mem = df.memory_usage().sum()/ 1024**2\n",
    "    numerics = ['int16','int32','int64','float16','float32','float64']\n",
    "    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                #NumPy分别提供numpy.iinfo 并numpy.finfo 验证NumPy整数和浮点值的最小值或最大值：\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                elif c_min > np.finfo(np.float64).min and c_max < np.finfo(np.float64).max:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "                    \n",
    "            end_men = df.memory_usage().sum()/1024**2\n",
    "    print('Memory usage after optimization is :{:.2f} MB'.format(end_men))\n",
    "    print('Decreased by {:1f}%'.format(100*(start_mem - end_men)/start_mem))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=============================================================================================================================\n",
    "\n",
    "# load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## question_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# question_data\n",
    "questions_df = pd.read_csv(f'{DATA_PATH}/questions.csv')\n",
    "questions_df['content_bundle_same'] = (questions_df['question_id'] == questions_df['bundle_id']).astype(int)  # 取出question_id 和 bundle_id：解决问题的代码。类别变量 相同的数据 9765个\n",
    "\n",
    "questions_df['tags_len'] = questions_df['tags'].apply(lambda x:0 if str(x)=='nan' else len(str(x).split(' '))) # 统计tags的个数 nan记为0\n",
    "\n",
    "questions_df['part_content_num'] = questions_df.groupby('part')['question_id'].transform('count') # 问题所属part的数量\n",
    "\n",
    "questions_df['tags'] = questions_df['tags'].apply(lambda x: [] if str(x) == 'nan' else str(x).split(' ')) # 切分tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_bundle_dict = dict(zip(questions_df.question_id.values,questions_df.bundle_id.values))\n",
    "question_part_dict = dict(zip(questions_df.question_id.values, questions_df.part.values))\n",
    "question_tags_dict = dict(zip(questions_df.question_id.values, questions_df.tags.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bundle_id\n",
       "1400        [1400, 1401, 1402]\n",
       "1403        [1403, 1404, 1405]\n",
       "1406        [1406, 1407, 1408]\n",
       "1409        [1409, 1410, 1411]\n",
       "1412        [1412, 1413, 1414]\n",
       "                 ...          \n",
       "13238    [13238, 13239, 13240]\n",
       "13241    [13241, 13242, 13243]\n",
       "13244    [13244, 13245, 13246]\n",
       "13247    [13247, 13248, 13249]\n",
       "13250    [13250, 13251, 13252]\n",
       "Name: question_id, Length: 1614, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bundle_df = questions_df.groupby('bundle_id')['question_id'].unique() # 相当于把list变成set 返回问题类别的所有唯一值\n",
    "bundle_df = bundle_df[bundle_df.apply(len)>1]  \n",
    "bundle_df # 找出同类问题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "bundle_mapping ={}\n",
    "for id_list in bundle_df.values:\n",
    "    bid = id_list[0]\n",
    "    for qid in id_list:\n",
    "        bundle_mapping[qid] = (bid,len(id_list))  #1400: (1400, 3) 找出一个类别有几个个数大于1的问题"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------------------------\n",
    "## lecture_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "lectures_df = pd.read_csv(f'{DATA_PATH}/lectures.csv')\n",
    "lecture_tag_dict = dict(zip(lectures_df.lecture_id.values, lectures_df.tag.values))  # 演讲的标签代码\n",
    "lecture_part_dict = dict(zip(lectures_df.lecture_id.values, lectures_df.part.values)) #  讲座的顶级类别代码\n",
    "lecture_type_dict = dict(zip(lectures_df.lecture_id.values, lectures_df.type_of.values)) # 简要介绍讲座的核心目的 解决问题类型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lecture_id</th>\n",
       "      <th>tag</th>\n",
       "      <th>part</th>\n",
       "      <th>type_of</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>89</td>\n",
       "      <td>159</td>\n",
       "      <td>5</td>\n",
       "      <td>concept</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>concept</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>185</td>\n",
       "      <td>45</td>\n",
       "      <td>6</td>\n",
       "      <td>concept</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>192</td>\n",
       "      <td>79</td>\n",
       "      <td>5</td>\n",
       "      <td>solving question</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>317</td>\n",
       "      <td>156</td>\n",
       "      <td>5</td>\n",
       "      <td>solving question</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>32535</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>solving question</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>32570</td>\n",
       "      <td>113</td>\n",
       "      <td>3</td>\n",
       "      <td>solving question</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>32604</td>\n",
       "      <td>24</td>\n",
       "      <td>6</td>\n",
       "      <td>concept</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>32625</td>\n",
       "      <td>142</td>\n",
       "      <td>2</td>\n",
       "      <td>concept</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>32736</td>\n",
       "      <td>82</td>\n",
       "      <td>3</td>\n",
       "      <td>concept</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     lecture_id  tag  part           type_of\n",
       "0            89  159     5           concept\n",
       "1           100   70     1           concept\n",
       "2           185   45     6           concept\n",
       "3           192   79     5  solving question\n",
       "4           317  156     5  solving question\n",
       "..          ...  ...   ...               ...\n",
       "413       32535    8     5  solving question\n",
       "414       32570  113     3  solving question\n",
       "415       32604   24     6           concept\n",
       "416       32625  142     2           concept\n",
       "417       32736   82     3           concept\n",
       "\n",
       "[418 rows x 4 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lectures_df.groupby('lecture_id').tail(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------------------------\n",
    "## train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5 µs, sys: 0 ns, total: 5 µs\n",
      "Wall time: 12.6 µs\n",
      "Train|Valid: 98730332|2500000\n",
      "Memory usage after optimization is :646.33 MB\n",
      "Decreased by 41.666662%\n",
      "Memory usage after optimization is :16.38 MB\n",
      "Decreased by 41.666486%\n",
      "Memory usage after optimization is :2636.38 MB\n",
      "Decreased by 26.315789%\n",
      "Memory usage after optimization is :66.76 MB\n",
      "Decreased by 26.315753%\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "if OFFLINE:\n",
    "    feld_needed = ['row_id', 'timestamp', 'user_id', 'content_id', 'content_type_id', 'task_container_id',\n",
    "                   'user_answer', 'answered_correctly', 'prior_question_elapsed_time', 'prior_question_had_explanation']\n",
    "    \n",
    "    if CV5:\n",
    "#             val_size = 250000\n",
    "        val_size = 2500000\n",
    "        train = dt.fread(DATA_PATH+file_train, max_nrows=None,columns=feld_needed).to_pandas()\n",
    "        valid_split1 = train.groupby('user_id').tail(5)  \n",
    "        train_split1 = train[~train.row_id.isin(valid_split1.row_id)]\n",
    "        valid_split1 = valid_split1[valid_split1.content_type_id == 0]\n",
    "        train_split1 = train_split1[train_split1.content_type_id == 0]\n",
    "        print(f'{train_split1.answered_correctly.mean():.3f} {valid_split1.answered_correctly.mean():.3f}')\n",
    "        \n",
    "        max_timestamp_u = train[['user_id','timestamp']].groupby(['user_id']).agg(['max']).reset_index()  # 得到每个用户最大的时间戳\n",
    "        max_timestamp_u.columns = ['user_id', 'max_time_stamp'] \n",
    "        MAX_TIME_STAMP = max_timestamp_u.max_time_stamp.max()  # 所有用户最大时间  因为是时间戳\n",
    "        # (MAX_TIME_STAMP for all users) - (max_time_stamp for each user)  所有用户的最大时间减去一个用户的最大时间就是这个用户开始的时间戳\n",
    "        def rand_time(max_time_stamp):\n",
    "            interval = MAX_TIME_STAMP - max_time_stamp\n",
    "            rand_time_stamp = random.randint(0,interval)\n",
    "            return rand_time_stamp\n",
    "        # 由于训练数据和测试数据是按时间拆分的，因此验证数据也应该按时间拆分。但是，给定的时间戳是自用户的第一个事件以来经过的时间，而不是实际时间。因此，我在一定间隔内为每个用户设置了随机的首次访问时间。\n",
    "        max_timestamp_u['rand_time_stamp'] = max_timestamp_u.max_time_stamp.apply(rand_time)\n",
    "        train = train.merge(max_timestamp_u, on='user_id', how='left')\n",
    "        train['viretual_time_stamp'] = train.timestamp + train['rand_time_stamp']\n",
    "        \n",
    "        train = train.sort_values(['viretual_time_stamp', 'row_id']).reset_index(drop=True)\n",
    "        #现在我们已经按viretual_time_amp对数据帧进行了排序，我们可以轻松地按时间拆分数据帧。\n",
    "        \n",
    "        for cv in range(5):\n",
    "            valid = train[-val_size:]\n",
    "            train = train[:-val_size]\n",
    "            # check new users and new contents\n",
    "            new_users = len(valid[~valid.user_id.isin(train.user_id)].user_id.unique())\n",
    "            valid_question = valid[valid.content_type_id == 0]\n",
    "            train_question = train[train.content_type_id == 0]\n",
    "            new_contents = len(valid_question[~valid_question.content_id.isin(train_question.content_id)].content_id.unique())    \n",
    "            print(f'cv{cv} {train_question.answered_correctly.mean():.3f} {valid_question.answered_correctly.mean():.3f} {new_users} {new_contents}')\n",
    "            valid.to_pickle(f'cv{cv+1}_valid.pickle')\n",
    "            train.to_pickle(f'cv{cv+1}_train.pickle')\n",
    "            \n",
    "    train = pd.read_pickle(f'./cv1_train.pickle')[feld_needed]\n",
    "    valid = pd.read_pickle(f'./cv1_valid.pickle')[feld_needed]\n",
    "    print(f'Train|Valid: {len(train)}|{len(valid)}')\n",
    "    \n",
    "    '''\n",
    "    Make feat for valid:\n",
    "    * ques: quest_train\n",
    "    * lect: lect_train\n",
    "\n",
    "    Make feat for test:\n",
    "    * ques: quest_train/quest_valid\n",
    "    * lect: lect_train/lect_valid\n",
    "    ''' \n",
    "    \n",
    "    # 训练集验证集都取出 问题的数据的这三列\n",
    "    ques_train = train.loc[train.content_type_id == False, ['row_id','content_id','answered_correctly']].reset_index(drop=True)\n",
    "    ques_valid = valid.loc[valid.content_type_id == False, ['row_id','content_id','answered_correctly']].reset_index(drop=True) \n",
    "    # 对他们进行量化\n",
    "    ques_train = reduce_mem_usage(ques_train, verbose=True)\n",
    "    ques_valid = reduce_mem_usage(ques_valid, verbose=True)\n",
    "    # 对验证集和训练集 的 用户在回答上一个问题包(忽略其间的任何讲座)后是否看到了解释和正确的回答 做填充\n",
    "    train['prior_question_had_explanation'] = train['prior_question_had_explanation'].fillna(False).astype('int8') \n",
    "    valid['prior_question_had_explanation'] = valid['prior_question_had_explanation'].fillna(False).astype('int8')\n",
    "    \n",
    "    # 对用户对问题包答题的nan进行均值填充\n",
    "    prior_question_elapsed_time_mean = train.loc[train.content_type_id == False].prior_question_elapsed_time.dropna().values.mean()\n",
    "    train['prior_question_elapsed_time'] = train['prior_question_elapsed_time'].fillna(prior_question_elapsed_time_mean).astype(np.int32)\n",
    "    valid['prior_question_elapsed_time'] = valid['prior_question_elapsed_time'].fillna(prior_question_elapsed_time_mean).astype(np.int32)\n",
    "    train = reduce_mem_usage(train, verbose=True)\n",
    "    valid = reduce_mem_usage(valid, verbose=True)\n",
    "    \n",
    "    save_pickle(prior_question_elapsed_time_mean, f'./prior_question_elapsed_time_mean.pkl')\n",
    "    config_dict = {}\n",
    "else:\n",
    "    config_dict = load_pickle(config_file)\n",
    "    prior_question_elapsed_time_mean = load_pickle(f'{CACHE_PATH}/prior_question_elapsed_time_mean.pkl')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13523"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(content_feat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------------------------------------------------------\n",
    "## Content static Feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_content_feat(df, type):\n",
    "    df = df.loc[df.content_type_id==False].reset_index(drop=True)\n",
    "    file_name = f'content_feat_{type}.pkl'\n",
    "    \n",
    "    # 每个题目的全局平均准确率\n",
    "    feat_df = df.groupby('content_id', as_index=False)['answered_correctly'].mean().rename(columns={'answered_correctly':'content_target_mean'})\n",
    "    # 每个题目全局出现次数\n",
    "    content_cnt = df.groupby('content_id')['user_id'].count()\n",
    "    feat_df['content_cnt'] = content_cnt.reindex(feat_df.content_id.values).values\n",
    "    \n",
    "    save_pickle(feat_df, save_path=f'./{file_name}')\n",
    "    feat_df = reduce_mem_usage(feat_df, verbose=True)\n",
    "    return feat_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage after optimization is :0.21 MB\n",
      "Decreased by 50.000000%\n",
      "Memory usage after optimization is :0.21 MB\n",
      "Decreased by 50.000000%\n",
      "content_feat:\n",
      "    content_id  content_target_mean  content_cnt\n",
      "0           0             0.907227         6777\n",
      "1           1             0.890625         7265\n",
      "2           2             0.554199        43781\n",
      "3           3             0.779297        22451\n",
      "4           4             0.613770        30881\n"
     ]
    }
   ],
   "source": [
    "if OFFLINE:\n",
    "    content_feat = make_content_feat(df=train.copy(deep=True),type='train')\n",
    "    content_feat_test = make_content_feat(df=pd.concat([train,valid]),type='test')\n",
    "    print('content_feat:\\n',content_feat.head())\n",
    "else:\n",
    "    content_feat_test = load_pickle(f'./content_feat_test.pkl')\n",
    "    content_feat_test = reduce_mem_usage(content_feat_test, verbose=True)\n",
    "    \n",
    "content_target_mean_dict = dict(zip(content_feat_test.content_id.values,\n",
    "                                    content_feat_test.content_target_mean.values))\n",
    "content_feat_cols = [col for col in content_feat_test if col != 'content_id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------------------------------------------------------\n",
    "## Part Fast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_part_mean_dict(df):\n",
    "    df = df.loc[df.content_type_id==False].reset_index(drop=True)\n",
    "    df = df.merge(questions_df[['question_id','part']], left_on='content_id', right_on='question_id',how='left')\n",
    "    \n",
    "    feat_df = df.groupby('part', as_index=False)['answered_correctly'].mean(). rename(columns={'answered_correctly': 'part_target_mean'})\n",
    "    return dict(zip(feat_df.part.values,feat_df.part_target_mean.values))\n",
    "\n",
    "if OFFLINE:\n",
    "    part_target_mean_dict = make_part_mean_dict(df=pd.concat([train[['content_id', 'content_type_id', 'answered_correctly']],\n",
    "                                                              valid[['content_id', 'content_type_id', 'answered_correctly']]]))\n",
    "    save_pickle(part_target_mean_dict, f'{CACHE_PATH}/part_target_mean_dict.pkl')\n",
    "else:\n",
    "    part_target_mean_dict = load_pickle(f'./part_target_mean_dict.pkl')\n",
    "    \n",
    "questions_df['part_target_mean'] = questions_df['part'].apply(lambda x: part_target_mean_dict[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------------------------------------------------------\n",
    "## Id static feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage after optimization is :1200.32 MB\n",
      "Decreased by 35.000000%\n",
      "Memory usage after optimization is :30.42 MB\n",
      "Decreased by 35.000000%\n"
     ]
    }
   ],
   "source": [
    "static_feat_cols = ['part','prior_question_elapsed_time']\n",
    "\n",
    "def get_stat_feat(df,feat_cols):\n",
    "    df = df.loc[df.content_type_id==False].reset_index(drop=True)\n",
    "    df = df.merge(questions_df[['question_id','part']],left_on='content_id',right_on='question_id',how='left')\n",
    "    return df[feat_cols]\n",
    "\n",
    "if OFFLINE:\n",
    "    state_feat_train = get_stat_feat(df=train.copy(deep=True), feat_cols=static_feat_cols)\n",
    "    state_feat_valid = get_stat_feat(df=valid.copy(deep=True), feat_cols=static_feat_cols)\n",
    "    state_feat_train = reduce_mem_usage(state_feat_train, verbose=True)\n",
    "    state_feat_valid = reduce_mem_usage(state_feat_valid, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96817414 2453886\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "98730332"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(state_feat_train),len(state_feat_valid))\n",
    "len(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------------------------------------------------------\n",
    "## User Loop Feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 25\n",
    "if OFFLINE:\n",
    "    user_cnt_dict = defaultdict(int) # 当字典里的key不存在但被查找时，返回的不是keyError而是一个默认值\n",
    "    user_pos_cnt_dict = defaultdict(int) # 比如list对应[ ]，str对应的是空字符串，set对应set( )，int对应0\n",
    "    user_part_cnt_dict = defaultdict(int)\n",
    "    user_part_pos_cnt_dict = defaultdict(int)\n",
    "    user_content_cnt_dict = defaultdict(int)\n",
    "    user_content_pos_cnt_dict = defaultdict(int)\n",
    "    user_content_redo_cnt_dict = defaultdict(int)\n",
    "    user_content_mean_sum_dict = defaultdict(int)\n",
    "    user_consecutive_pos_cnt_dict = defaultdict(int)\n",
    "    user_target_win25_dict = defaultdict(list)\n",
    "    user_content_mean_win10_dict = defaultdict(list)\n",
    "\n",
    "    user_explanation_cnt_dict = defaultdict(int)\n",
    "    user_explanation_pos_cnt_dict = defaultdict(int)\n",
    "    user_elapse_time_sum_dict = defaultdict(int)\n",
    "    user_elapse_time_win10_dict = defaultdict(list)\n",
    "    user_last_timestamp_dict = defaultdict(int)\n",
    "    user_last_task_dict = defaultdict(int)\n",
    "    user_content_win5_dict = defaultdict(list)\n",
    "    user_part_win10_dict = defaultdict(list)\n",
    "\n",
    "    bundle_state_dict = defaultdict(list) # bundle_id, time_diff\n",
    "    # user_order_in_session_dict = defaultdict(int)\n",
    "    user_cum_time_dict = defaultdict(int)\n",
    "    user_timespan_win10_dict = defaultdict(list)\n",
    "\n",
    "    user_tags_cnt_dict = defaultdict(int)\n",
    "    user_tags_pos_cnt_dict = defaultdict(int)\n",
    "\n",
    "    user_continue_quest_cnt_dict = defaultdict(int)\n",
    "else:\n",
    "    user_content_feat_df = pd.read_pickle(f'{CACHE_PATH}/user_content_feat.pkl')\n",
    "    user_content_feat_df = reduce_mem_usage(user_content_feat_df)\n",
    "    user_content_cnt_dict = defaultdict(int)\n",
    "    user_content_pos_cnt_dict = defaultdict(int)\n",
    "\n",
    "    user_cnt_dict = load_pickle(f'{CACHE_PATH}/user_cnt_dict.pkl')\n",
    "    user_pos_cnt_dict = load_pickle(f'{CACHE_PATH}/user_pos_cnt_dict.pkl')\n",
    "    user_part_cnt_dict = load_pickle(f'{CACHE_PATH}/user_part_cnt_dict.pkl')\n",
    "    user_part_pos_cnt_dict = load_pickle(f'{CACHE_PATH}/user_part_pos_cnt_dict.pkl')\n",
    "    # user_content_cnt_dict = load_pickle(f'{CACHE_PATH}/user_content_cnt_dict.pkl')\n",
    "    user_content_redo_cnt_dict = load_pickle(f'{CACHE_PATH}/user_content_redo_cnt_dict.pkl')\n",
    "    user_content_mean_sum_dict = load_pickle(f'{CACHE_PATH}/user_content_mean_sum_dict.pkl')\n",
    "    user_consecutive_pos_cnt_dict = load_pickle(f'{CACHE_PATH}/user_consecutive_pos_cnt_dict.pkl')\n",
    "    user_target_win25_dict = load_pickle(f'{CACHE_PATH}/user_target_win25_dict.pkl')\n",
    "    user_content_mean_win10_dict = load_pickle(f'{CACHE_PATH}/user_content_mean_win10_dict.pkl')\n",
    "\n",
    "    user_explanation_cnt_dict = load_pickle(f'{CACHE_PATH}/user_explanation_cnt_dict.pkl')\n",
    "    user_explanation_pos_cnt_dict = load_pickle(f'{CACHE_PATH}/user_explanation_pos_cnt_dict.pkl')\n",
    "    user_elapse_time_sum_dict = load_pickle(f'{CACHE_PATH}/user_elapse_time_sum_dict.pkl')\n",
    "    user_elapse_time_win10_dict = load_pickle(f'{CACHE_PATH}/user_elapse_time_win10_dict.pkl')\n",
    "    user_last_timestamp_dict = load_pickle(f'{CACHE_PATH}/user_last_timestamp_dict.pkl')\n",
    "    user_last_task_dict = load_pickle(f'{CACHE_PATH}/user_last_task_dict.pkl')\n",
    "    user_content_win5_dict = load_pickle(f'{CACHE_PATH}/user_content_win5_dict.pkl')\n",
    "    user_part_win10_dict = load_pickle(f'{CACHE_PATH}/user_part_win10_dict.pkl')\n",
    "\n",
    "    bundle_state_dict = load_pickle(f'{CACHE_PATH}/bundle_state_dict.pkl')\n",
    "    # user_order_in_session_dict = load_pickle(f'{CACHE_PATH}/user_order_in_session_dict.pkl')\n",
    "    user_cum_time_dict = load_pickle(f'{CACHE_PATH}/user_cum_time_dict.pkl')\n",
    "    user_timespan_win10_dict = load_pickle(f'{CACHE_PATH}/user_timespan_win10_dict.pkl')\n",
    "\n",
    "    user_tags_cnt_dict = load_pickle(f'{CACHE_PATH}/user_tags_cnt_dict.pkl')\n",
    "    user_tags_pos_cnt_dict = load_pickle(f'{CACHE_PATH}/user_tags_pos_cnt_dict.pkl')\n",
    "\n",
    "    user_continue_quest_cnt_dict = load_pickle(f'{CACHE_PATH}/user_continue_quest_cnt_dict.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "used_cols = ['user_id', 'content_id', 'task_container_id', 'answered_correctly', 'prior_question_elapsed_time',\n",
    "             'prior_question_had_explanation', 'content_type_id', 'timestamp']\n",
    "\n",
    "def make_user_loop_feature(df, content_target_mean_dict,\n",
    "                          user_cnt_dict, \n",
    "                          user_pos_cnt_dict,\n",
    "                          user_part_cnt_dict,\n",
    "                          user_part_pos_cnt_dict,\n",
    "                          user_content_cnt_dict,\n",
    "                          user_content_pos_cnt_dict,\n",
    "                          user_content_redo_cnt_dict,\n",
    "                          user_content_mean_sum_dict,\n",
    "                          user_consecutive_pos_cnt_dict, \n",
    "                          user_target_win25_dict, \n",
    "                          user_content_mean_win10_dict,\n",
    "                          user_explanation_cnt_dict,\n",
    "                          user_explanation_pos_cnt_dict, \n",
    "                          user_elapse_time_sum_dict,\n",
    "                          user_elapse_time_win10_dict,\n",
    "                          user_last_timestamp_dict,\n",
    "                          user_last_task_dict,\n",
    "                          user_content_win5_dict,\n",
    "                          user_part_win10_dict,\n",
    "                          bundle_state_dict,\n",
    "                          user_cum_time_dict, \n",
    "                          user_timespan_win10_dict,# user_order_in_session_dict,\n",
    "                          user_tags_cnt_dict,\n",
    "                          user_tags_pos_cnt_dict,\n",
    "                          user_continue_quest_cnt_dict,\n",
    "                          update=True, isTrain=True):\n",
    "    sample_num = len(df.loc[df.content_type_id == False])\n",
    "\n",
    "    user_cnt_npy = np.zeros(sample_num)\n",
    "    user_pos_cnt_npy = np.zeros(sample_num)\n",
    "    user_part_cnt_npy = np.zeros(sample_num)\n",
    "    user_part_pos_cnt_npy = np.zeros(sample_num)\n",
    "    user_content_cnt_npy = np.zeros(sample_num)\n",
    "    user_content_pos_cnt_npy = np.zeros(sample_num)\n",
    "    user_content_redo_cnt_npy = np.zeros(sample_num)\n",
    "    user_content_mean_mean_npy = np.zeros(sample_num)\n",
    "    user_consecutive_pos_cnt_npy = np.zeros(sample_num)\n",
    "    user_pos_cnt_win25_npy = np.zeros(sample_num)\n",
    "    user_content_mean_win10_npy = np.zeros(sample_num)\n",
    "\n",
    "    user_explanation_cnt_npy = np.zeros(sample_num)\n",
    "    user_explanation_pos_cnt_npy = np.zeros(sample_num)\n",
    "    user_elapse_time_mean_npy = np.zeros(sample_num)\n",
    "    user_elapse_time_mean_win10_npy = np.zeros(sample_num)\n",
    "    user_last_timespan_npy = np.zeros(sample_num)\n",
    "    user_last_task_diff_npy = np.zeros(sample_num)\n",
    "    user_content_appear_in_win5_npy = np.zeros(sample_num)\n",
    "    user_part_cnt_in_win10_npy = np.zeros(sample_num)\n",
    "\n",
    "    # user_order_in_session_npy = np.zeros(sample_num)\n",
    "    user_cum_time_npy = np.zeros(sample_num)\n",
    "    user_timespan_win10_mean_npy = np.zeros(sample_num)\n",
    "\n",
    "    user_tags_cnt_mean_npy = np.zeros(sample_num)\n",
    "    user_tags_pos_rate_npy = np.zeros(sample_num)\n",
    "\n",
    "    user_continue_quest_cnt_npy = np.zeros(sample_num)\n",
    "\n",
    "    if update:\n",
    "        tk0 = tqdm(df[used_cols].values)\n",
    "    else:\n",
    "        tk0 = df[used_cols].values\n",
    "    idx = 0\n",
    "    for(_user_id,_content_id,_task_container_id, _answered_correctly, _prior_question_elapsed_time,\n",
    "           _prior_question_had_explanation, _content_type_id, _timestamp) in tk0:\n",
    "        \n",
    "        if _content_id in content_target_mean_dict:\n",
    "            _content_target_mean = content_target_mean_dict[_content_id]\n",
    "        else:\n",
    "            _content_target_mean = 0\n",
    "            \n",
    "        if _content_type_id == False:\n",
    "            _bundle_id = question_bundle_dict[_content_id]\n",
    "        else:\n",
    "            _content_target_mean=0\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
